{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "049c3333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccfc90d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../utils')\n",
    "from models import imagenet_resnet\n",
    "import load\n",
    "import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ef5f891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this loads the state dictionary from all the checkpoints in the folder, averages the last n, tensor by tensor,\n",
    "# and returns the average state dictionary\n",
    "\n",
    "def load_cache_ave_n(save_dir, experiment, expid, metric, n):\n",
    "    exp_path = f\"{save_dir}/{experiment}/{expid}\"\n",
    "    step_names = glob.glob(f\"{exp_path}/ckpt/*.tar\")\n",
    "    step_list = [int(s.split(\".tar\")[0].split(\"step\")[1]) for s in step_names]\n",
    "    steps, cache = [], []\n",
    "    i = 0\n",
    "    current_check = 0\n",
    "    temp = sorted(list(zip(step_names, step_list)), key=lambda x: x[1])\n",
    "    for in_filename, step in tqdm(temp[-n:]):\n",
    "        \n",
    "        checkpoint = torch.load(in_filename)\n",
    "        \n",
    "        if i == 0:\n",
    "            print(\"There are \",  len(checkpoint[\"model_state_dict\"].keys()), \" tensors in this model\" )\n",
    "            i+=1\n",
    "            \n",
    "        if current_check == 0:\n",
    "            new_model = checkpoint[\"model_state_dict\"].copy()\n",
    "        else:\n",
    "            for key in checkpoint[\"model_state_dict\"].keys():\n",
    "                new_model[key] = new_model[key]+checkpoint[\"model_state_dict\"][key]\n",
    "        current_check+=1\n",
    "        \n",
    "    for key in new_model.keys():\n",
    "        new_model[key]=new_model[key]/current_check\n",
    "    \n",
    "    print(\"Averaged over \",current_check , \"checkpoints\")\n",
    "    return new_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c2e375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives the accuracy as a function of how many checkpoints this has been averaged over, from the last one\n",
    "dir_exp=\"../results\" ##Here the directory where the experiments are stored\n",
    "metric = \"test_accuracy1\"\n",
    "input_shape, num_classes = load.dimension(\"tiny-imagenet\")\n",
    "CACHE_PATH = dir_exp\n",
    "all_accs = []\n",
    "experiment=  \"run-ECD\"  ##name of the saved experiment\n",
    "\n",
    "\n",
    "expid = str(1)    \n",
    "\n",
    "accuracies = []\n",
    "for n_to_average in range(1,11):\n",
    "    # This returns the averaged parameters\n",
    "    averaged_model = load_cache_ave_n(CACHE_PATH, experiment, expid, metric, n_to_average)\n",
    "\n",
    "\n",
    "    model = load.model('resnet18','imagenet')(\n",
    "            input_shape=input_shape, num_classes=num_classes, pretrained=False,\n",
    "            model_dir=\"\",\n",
    "        )\n",
    "    model.load_state_dict(averaged_model)\n",
    "    torch.cuda.set_device(0)\n",
    "    model.to(torch.device(\"cuda\"))\n",
    "\n",
    "    #Now evaluate the performance of this averaged network\n",
    "    ## Number epoch does not mean anything here \n",
    "\n",
    "    test_loader = load.dataloader(\n",
    "        dataset=\"imagenet\",\n",
    "        batch_size=128,\n",
    "        train=False,\n",
    "        workers=2,\n",
    "        datadir=\"../data\",#directory where the dataset is stored\n",
    "        tpu=False,\n",
    "    )\n",
    "    res = optimize.eval(model, load.loss(\"ce\"), test_loader, torch.device(\"cuda\"), False, 0)\n",
    "    accuracies.append(res[1])\n",
    "all_accs.append(accuracies)\n",
    "    \n",
    "with open(experiment+\"accuracies.json\", \"w\") as outfile:\n",
    "    json.dump(all_accs, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc9000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"run-ECD\"\n",
    "with open(experiment+\"accuracies.json\", \"r\") as outfile:\n",
    "    all_accs = json.load(outfile)\n",
    "\n",
    "maxes  =[]\n",
    "for accuracies in all_accs:\n",
    "    maxes.append(max(accuracies))\n",
    "print(max(maxes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3 (main, Apr  5 2023, 00:00:00) [GCC 12.2.1 20221121 (Red Hat 12.2.1-4)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
